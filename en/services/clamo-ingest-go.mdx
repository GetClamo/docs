---
title: clamo-ingest-go
description: High-performance worker for data ingestion from Kafka
---

# clamo-ingest-go

High-performance Go worker for data ingestion from Kafka to tenant databases. Consumes events from the `cej.case.ready` topic and inserts them into the corresponding databases.

## General Information

| Property | Value |
|----------|-------|
| **Repository** | `GetClamo/clamo-ingest-go` |
| **Language** | Go 1.22 |
| **Messaging** | Kafka |
| **Database** | PostgreSQL (pgx) |
| **Cache** | LRU for tenant connections |

## Architecture

```mermaid
flowchart LR
    subgraph Input [Input]
        Kafka[(Kafka<br/>cej.case.ready)]
    end
    
    subgraph Worker [clamo-ingest-go]
        Consumer[Consumer Group]
        Validator[Validator]
        Router[Tenant Router]
        BatchWriter[Batch Writer]
    end
    
    subgraph TenantSDK [Resolution]
        TenantService[clamo-tenant<br/>/internal/v1/...]
        Vault[(Supabase Vault)]
    end
    
    subgraph Output [Tenant DBs]
        T1[(Tenant 1)]
        T2[(Tenant 2)]
        T3[(Tenant 3)]
    end
    
    Kafka --> Consumer
    Consumer --> Validator
    Validator --> Router
    Router --> TenantSDK
    TenantSDK --> Vault
    Router --> BatchWriter
    BatchWriter --> T1
    BatchWriter --> T2
    BatchWriter --> T3
```

## Processing Flow

1. **Consume**: Read messages from `cej.case.ready` topic
2. **Validate**: Verify event structure
3. **Group**: Group by `companyId` for batch insert
4. **Resolve**: Get connection string via Tenant SDK
5. **Insert**: Use `COPY` or upsert for bulk insertion
6. **Commit**: Confirm offset in Kafka

## Implementation

### Consumer

```go
type Worker struct {
    reader      *kafka.Reader
    tenantPool  *TenantConnectionPool
    batchSize   int
    flushPeriod time.Duration
}

func (w *Worker) Run(ctx context.Context) error {
    batch := make([]CaseReadyEvent, 0, w.batchSize)
    ticker := time.NewTicker(w.flushPeriod)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return w.flush(batch)
            
        case <-ticker.C:
            if len(batch) > 0 {
                if err := w.flush(batch); err != nil {
                    log.Error("flush error", "error", err)
                }
                batch = batch[:0]
            }
            
        default:
            msg, err := w.reader.FetchMessage(ctx)
            if err != nil {
                continue
            }
            
            var event CaseReadyEvent
            if err := json.Unmarshal(msg.Value, &event); err != nil {
                log.Error("unmarshal error", "error", err)
                continue
            }
            
            batch = append(batch, event)
            
            if len(batch) >= w.batchSize {
                if err := w.flush(batch); err != nil {
                    log.Error("flush error", "error", err)
                }
                batch = batch[:0]
            }
            
            w.reader.CommitMessages(ctx, msg)
        }
    }
}
```

### Batch Insert

```go
func (w *Worker) flush(events []CaseReadyEvent) error {
    // Group by tenant
    byTenant := make(map[string][]Case)
    for _, event := range events {
        byTenant[event.CompanyID] = append(
            byTenant[event.CompanyID],
            event.Cases...,
        )
    }
    
    // Insert per tenant in parallel
    g, ctx := errgroup.WithContext(context.Background())
    
    for companyID, cases := range byTenant {
        companyID, cases := companyID, cases
        g.Go(func() error {
            return w.insertCases(ctx, companyID, cases)
        })
    }
    
    return g.Wait()
}
```

### Tenant Connection Pool

```go
type TenantConnectionPool struct {
    tenantClient *TenantSDKClient
    connections  sync.Map // map[string]*pgxpool.Pool
}

func (p *TenantConnectionPool) Get(companyID string) (*pgxpool.Pool, error) {
    // Check cache
    if conn, ok := p.connections.Load(companyID); ok {
        return conn.(*pgxpool.Pool), nil
    }
    
    // Get connection string from Tenant SDK
    connStr, err := p.tenantClient.GetDatabaseConnection(companyID)
    if err != nil {
        return nil, err
    }
    
    // Create pool
    config, err := pgxpool.ParseConfig(connStr)
    if err != nil {
        return nil, err
    }
    
    config.MaxConns = 10
    config.MinConns = 2
    config.MaxConnLifetime = 30 * time.Minute
    
    pool, err := pgxpool.NewWithConfig(context.Background(), config)
    if err != nil {
        return nil, err
    }
    
    p.connections.Store(companyID, pool)
    return pool, nil
}
```

## Respecting Trusted Sources

The worker respects the source hierarchy when inserting:

```go
func (w *Worker) upsertCase(ctx context.Context, conn *pgxpool.Conn, c Case) error {
    // Only update CEJ fields, preserve manual
    _, err := conn.Exec(ctx, `
        INSERT INTO cases (
            id, case_number, company_id,
            subject_matter, process_type, stage,
            cej_judicial_district, court, judge,
            created_at, updated_at
        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
        ON CONFLICT (case_number, company_id) DO UPDATE SET
            -- Only update SourcedValue.cej, preserve ai and manual
            subject_matter = jsonb_set(
                COALESCE(cases.subject_matter, '{}'),
                '{cej}',
                EXCLUDED.subject_matter->'cej'
            ),
            -- Direct CEJ fields are overwritten
            cej_judicial_district = EXCLUDED.cej_judicial_district,
            court = EXCLUDED.court,
            judge = EXCLUDED.judge,
            updated_at = EXCLUDED.updated_at
    `, c.ID, c.CaseNumber, c.CompanyID, /* ... */)
    
    return err
}
```

## Configuration

### Environment Variables

```bash
# Kafka
KAFKA_BROKERS=localhost:9092
KAFKA_TOPIC=cej.case.ready
KAFKA_GROUP_ID=clamo-ingest

# Tenant SDK
TENANT_SERVICE_URL=http://localhost:4001

# Worker
BATCH_SIZE=1000
FLUSH_PERIOD=5s
MAX_WORKERS=10
```

### Docker

```dockerfile
FROM golang:1.22-alpine AS builder

WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download

COPY . .
RUN CGO_ENABLED=0 go build -o /ingest ./cmd/worker

FROM alpine:latest
RUN apk --no-cache add ca-certificates
COPY --from=builder /ingest /ingest
CMD ["/ingest"]
```

## Metrics

```go
var (
    messagesProcessed = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "ingest_messages_processed_total",
            Help: "Total messages processed",
        },
        []string{"status", "company_id"},
    )
    
    batchSize = promauto.NewHistogram(
        prometheus.HistogramOpts{
            Name:    "ingest_batch_size",
            Help:    "Size of processed batches",
            Buckets: []float64{10, 50, 100, 500, 1000},
        },
    )
    
    insertLatency = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "ingest_insert_latency_seconds",
            Help:    "Latency of batch inserts",
            Buckets: prometheus.DefBuckets,
        },
        []string{"company_id"},
    )
)
```

## Local Development

```bash
# Build
go build -o bin/ingest ./cmd/worker

# Run
./bin/ingest

# Tests
go test ./...

# Benchmark
go test -bench=. ./...
```

## Next Steps

<CardGroup cols={2}>
  <Card
    title="clamo-cej-connector"
    icon="plug"
    href="/en/services/clamo-cej-connector"
  >
    Service that produces events to Kafka.
  </Card>
  <Card
    title="Data Model"
    icon="database"
    href="/en/architecture/data-model"
  >
    SourcedValue pattern and source hierarchy.
  </Card>
</CardGroup>
